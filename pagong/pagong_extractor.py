"""
Pagong Extractor - í†µí•© PDF ìˆ˜ì§‘ ë° ì²˜ë¦¬ ì‹œìŠ¤í…œ
ë²•ì› ê³µê³  PDFë¥¼ ìˆ˜ì§‘í•˜ê³  ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œ

ë™ì‘ ë°©ì‹:
1. Court Crawler ì‹¤í–‰ (ì˜µì…˜):
   - ë²•ì› ì‚¬ì´íŠ¸ì—ì„œ ìƒˆë¡œìš´ PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ
   - data/[ID]/pdf/ í´ë”ì— ì €ì¥
   
2. PDF ì²˜ë¦¬:
   - data í´ë” ë‚´ì˜ ëª¨ë“  ID í´ë”ë¥¼ ìˆ«ì ì—­ìˆœìœ¼ë¡œ ì •ë ¬
   - ê° ID í´ë”ì—ì„œ:
     * pdf í´ë”ê°€ ìˆê³ , img/text í´ë”ê°€ ì—†ìœ¼ë©´
     * pdf í´ë” ë‚´ì˜ PDF íŒŒì¼ì„ pdf_extractorë¡œ ì²˜ë¦¬
     * ê²°ê³¼ë¥¼ í•´ë‹¹ ID í´ë”ì— ì €ì¥
   - ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ë¥¼ ë§Œë‚˜ë©´ ì¤‘ë‹¨

ì‚¬ìš©ë²•:
  python pagong_extractor.py                    # í¬ë¡¤ëŸ¬ ì‹¤í–‰ í›„ PDF ì²˜ë¦¬
  python pagong_extractor.py --no-crawler       # PDF ì²˜ë¦¬ë§Œ ìˆ˜í–‰
  python pagong_extractor.py --dry-run          # ì²˜ë¦¬ ëŒ€ìƒë§Œ í™•ì¸
  python pagong_extractor.py --data-dir custom  # ì»¤ìŠ¤í…€ data í´ë”
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple
import re
from pdf_extractor import PDFExtractor
from pdf_crawler import CourtCrawler, CrawlerConfig


class PagongExtractor:
    """data í´ë”ì˜ PDFë“¤ì„ ì¼ê´„ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: str = "data"):
        """
        ì´ˆê¸°í™”
        
        Args:
            data_dir: data í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: "data")
        """
        self.data_dir = data_dir
        self.pdf_extractor = PDFExtractor()
        self.processed_count = 0
        self.skipped_count = 0
        self.error_count = 0
        
    def run(self, run_crawler: bool = True):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
        
        Args:
            run_crawler: court_crawlerë¥¼ ë¨¼ì € ì‹¤í–‰í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        print("ğŸš€ Pagong Extractor ì‹œì‘")
        print(f"ğŸ“ data í´ë” ê²½ë¡œ: {self.data_dir}")
        print("="*60)
        
        # 1. Court Crawler ì‹¤í–‰ (ì˜µì…˜)
        if run_crawler:
            print("\nğŸ“¥ Court Crawler ì‹¤í–‰ ì¤‘...")
            print("="*60)
            try:
                # í¬ë¡¤ëŸ¬ ì„¤ì •
                crawler_config = CrawlerConfig()
                crawler_config.DOWNLOAD_FOLDER_NAME = self.data_dir  # ê°™ì€ data í´ë” ì‚¬ìš©
                
                # í¬ë¡¤ëŸ¬ ì‹¤í–‰
                with CourtCrawler(crawler_config) as crawler:
                    crawler.run()
                
                print("\nâœ… Court Crawler ì™„ë£Œ!")
                print("="*60)
            except Exception as e:
                print(f"\nâš ï¸  Court Crawler ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                print("PDF ì²˜ë¦¬ëŠ” ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
                print("="*60)
        
        # data í´ë” ì¡´ì¬ í™•ì¸
        if not os.path.exists(self.data_dir):
            print(f"âŒ data í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_dir}")
            return
        
        # ID í´ë”ë“¤ ì°¾ê¸° ë° ì •ë ¬
        id_folders = self._get_sorted_id_folders()
        
        if not id_folders:
            print("âš ï¸  ì²˜ë¦¬í•  ID í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“‹ PDF ì²˜ë¦¬ ì‹œì‘")
        print("="*60)
        print(f"ğŸ“Š ë°œê²¬ëœ ID í´ë”: {len(id_folders)}ê°œ")
        print(f"ğŸ“‹ ì²˜ë¦¬ ìˆœì„œ (ìˆ«ì ë†’ì€ ìˆœ): {id_folders[:5]}{'...' if len(id_folders) > 5 else ''}")
        print("="*60)
        
        # ê° ID í´ë” ì²˜ë¦¬
        for idx, id_folder in enumerate(id_folders, 1):
            print(f"\n[{idx}/{len(id_folders)}] ID: {id_folder}")
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ì¸ì§€ í™•ì¸
            id_path = os.path.join(self.data_dir, id_folder)
            img_dir = os.path.join(id_path, "img")
            text_dir = os.path.join(id_path, "text")
            
            if os.path.exists(img_dir) or os.path.exists(text_dir):
                print(f"  ğŸ›‘ img/text í´ë”ê°€ ì´ë¯¸ ì¡´ì¬ - ì—¬ê¸°ì„œ ì •ì§€")
                print(f"     (ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ íŒë‹¨)")
                self.skipped_count += 1
                break
            
            # í´ë” ì²˜ë¦¬
            self._process_id_folder(id_folder)
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        self._print_summary()
    
    def _get_sorted_id_folders(self) -> List[str]:
        """
        data í´ë” ë‚´ì˜ ID í´ë”ë“¤ì„ ì°¾ì•„ì„œ ìˆ«ì ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        
        Returns:
            ì •ë ¬ëœ ID í´ë”ëª… ë¦¬ìŠ¤íŠ¸
        """
        id_folders = []
        
        for item in os.listdir(self.data_dir):
            item_path = os.path.join(self.data_dir, item)
            if os.path.isdir(item_path):
                # í´ë”ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ ì‹œë„
                match = re.match(r'^(\d+)', item)
                if match:
                    id_num = int(match.group(1))
                    id_folders.append((id_num, item))
        
        # ìˆ«ì ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        id_folders.sort(key=lambda x: x[0], reverse=True)
        
        # í´ë”ëª…ë§Œ ë°˜í™˜
        return [folder_name for _, folder_name in id_folders]
    
    def _process_id_folder(self, id_folder: str):
        """
        ê°œë³„ ID í´ë” ì²˜ë¦¬
        
        Args:
            id_folder: ID í´ë”ëª…
        """
        id_path = os.path.join(self.data_dir, id_folder)
        
        # í•˜ìœ„ í´ë” í™•ì¸
        pdf_dir = os.path.join(id_path, "pdf")
        img_dir = os.path.join(id_path, "img")
        text_dir = os.path.join(id_path, "text")
        
        # pdf í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not os.path.exists(pdf_dir):
            print(f"  â­ï¸  pdf í´ë” ì—†ìŒ - ê±´ë„ˆëœ€")
            self.skipped_count += 1
            return
        
        
        # pdf í´ë” ë‚´ì˜ PDF íŒŒì¼ ì°¾ê¸°
        pdf_files = self._find_pdf_files(pdf_dir)
        
        if not pdf_files:
            print(f"  âš ï¸  pdf í´ë”ì— PDF íŒŒì¼ ì—†ìŒ")
            self.skipped_count += 1
            return
        
        # ì²« ë²ˆì§¸ PDF íŒŒì¼ ì²˜ë¦¬ (ë³´í†µ í•˜ë‚˜ë§Œ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ)
        pdf_file = pdf_files[0]
        print(f"  ğŸ“„ PDF íŒŒì¼ ë°œê²¬: {os.path.basename(pdf_file)}")
        
        try:
            # PDF ì¶”ì¶œ ì‹¤í–‰ - ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ID í´ë”ë¡œ ì§ì ‘ ì§€ì •
            print(f"  ğŸ”„ ì¶”ì¶œ ì‹œì‘...")
            print(f"     - PDF ê²½ë¡œ: {pdf_file}")
            print(f"     - ì¶œë ¥ ê²½ë¡œ: {id_path}")
            
            result = self.pdf_extractor.extract(pdf_file, output_dir=id_path)
            
            if result['success']:
                print(f"  âœ… ì¶”ì¶œ ì„±ê³µ!")
                print(f"     - ì´ë¯¸ì§€: {result['image_count']}ê°œ")
                print(f"     - í…ìŠ¤íŠ¸ í˜ì´ì§€: {result['text_page_count']}ê°œ")
                print(f"     - ìŠ¤ìº”ë³¸ ì—¬ë¶€: {result.get('is_scanned_doc', False)}")
                if result.get('has_scan_folder'):
                    print(f"     - ğŸ“‹ scan í´ë” ìƒì„±ë¨")
                
                # ìƒì„±ëœ í´ë” í™•ì¸
                created_dirs = []
                if os.path.exists(os.path.join(id_path, "img")):
                    created_dirs.append("img")
                if os.path.exists(os.path.join(id_path, "text")):
                    created_dirs.append("text")
                if os.path.exists(os.path.join(id_path, "scan")):
                    created_dirs.append("scan")
                print(f"     - ìƒì„±ëœ í´ë”: {', '.join(created_dirs)}")
                
                self.processed_count += 1
            else:
                print(f"  âŒ ì¶”ì¶œ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                self.error_count += 1
                
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            self.error_count += 1
    
    def _find_pdf_files(self, pdf_dir: str) -> List[str]:
        """
        ë””ë ‰í† ë¦¬ì—ì„œ PDF íŒŒì¼ ì°¾ê¸°
        
        Args:
            pdf_dir: PDF ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        pdf_files = []
        
        for file in os.listdir(pdf_dir):
            if file.lower().endswith('.pdf'):
                pdf_files.append(os.path.join(pdf_dir, file))
        
        return pdf_files
    
    def _print_summary(self):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"âœ… ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬: {self.processed_count}ê°œ")
        print(f"â­ï¸  ê±´ë„ˆë›´ í´ë”: {self.skipped_count}ê°œ")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {self.error_count}ê°œ")
        print(f"ğŸ“ ì „ì²´: {self.processed_count + self.skipped_count + self.error_count}ê°œ")
        print("="*60)
        print("âœ¨ Pagong Extractor ì™„ë£Œ!")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ë²•ì› ê³µê³  PDFë¥¼ ìˆ˜ì§‘í•˜ê³  ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python pagong_extractor.py                        # í¬ë¡¤ëŸ¬ ì‹¤í–‰ í›„ PDF ì²˜ë¦¬ (ê¸°ë³¸)
  python pagong_extractor.py --no-crawler           # PDF ì²˜ë¦¬ë§Œ ìˆ˜í–‰ (í¬ë¡¤ëŸ¬ ê±´ë„ˆëœ€)
  python pagong_extractor.py --dry-run              # ì‹¤ì œ ì²˜ë¦¬í•˜ì§€ ì•Šê³  í™•ì¸ë§Œ
  python pagong_extractor.py --data-dir custom_data # ì»¤ìŠ¤í…€ í´ë” ì²˜ë¦¬
  
ë™ì‘ ìˆœì„œ:
  1. Court Crawlerë¡œ ìƒˆë¡œìš´ PDF ë‹¤ìš´ë¡œë“œ (--no-crawler ì˜µì…˜ ì—†ì„ ë•Œ)
  2. ë‹¤ìš´ë¡œë“œëœ PDFì—ì„œ ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ì¶”ì¶œ
  3. ìŠ¤ìº”ë³¸ì¸ ê²½ìš° scan í´ë” ì¶”ê°€ ìƒì„±
        """
    )
    
    parser.add_argument(
        "--data-dir", 
        default="data",
        help="ì²˜ë¦¬í•  data í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: data)"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤ì œ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ì²˜ë¦¬ ëŒ€ìƒë§Œ í™•ì¸"
    )
    
    parser.add_argument(
        "--no-crawler",
        action="store_true",
        help="court_crawlerë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šê³  PDF ì²˜ë¦¬ë§Œ ìˆ˜í–‰"
    )
    
    args = parser.parse_args()
    
    # Dry run ëª¨ë“œ
    if args.dry_run:
        print("ğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ëŒ€ìƒë§Œ í™•ì¸í•©ë‹ˆë‹¤.")
        extractor = PagongExtractor(args.data_dir)
        id_folders = extractor._get_sorted_id_folders()
        
        print(f"ğŸ“ data í´ë”: {args.data_dir}")
        print(f"ğŸ“Š ë°œê²¬ëœ ID í´ë”: {len(id_folders)}ê°œ")
        print("\nì²˜ë¦¬ ëŒ€ìƒ ID í´ë” ëª©ë¡:")
        
        for idx, id_folder in enumerate(id_folders, 1):
            id_path = os.path.join(args.data_dir, id_folder)
            pdf_dir = os.path.join(id_path, "pdf")
            img_dir = os.path.join(id_path, "img")
            text_dir = os.path.join(id_path, "text")
            
            status = "â­ï¸ ê±´ë„ˆëœ€"
            reason = ""
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ë©´ ì—¬ê¸°ì„œ ì¤‘ë‹¨
            if os.path.exists(img_dir) or os.path.exists(text_dir):
                print(f"{idx:4d}. {id_folder:20s} ğŸ›‘ ì •ì§€ (img/text ì´ë¯¸ ì¡´ì¬)")
                print("\nâš ï¸  ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ë¥¼ ë§Œë‚˜ ì—¬ê¸°ì„œ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
                break
            
            if not os.path.exists(pdf_dir):
                reason = "(pdf í´ë” ì—†ìŒ)"
            else:
                pdf_files = []
                if os.path.exists(pdf_dir):
                    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith('.pdf')]
                if pdf_files:
                    status = "âœ… ì²˜ë¦¬ ëŒ€ìƒ"
                    reason = f"(PDF: {pdf_files[0]})"
                else:
                    reason = "(PDF íŒŒì¼ ì—†ìŒ)"
            
            print(f"{idx:4d}. {id_folder:20s} {status} {reason}")
        
        return
    
    # ì‹¤ì œ ì‹¤í–‰
    extractor = PagongExtractor(args.data_dir)
    # --no-crawler ì˜µì…˜ì´ ì—†ìœ¼ë©´ í¬ë¡¤ëŸ¬ ì‹¤í–‰ (ê¸°ë³¸ê°’: í¬ë¡¤ëŸ¬ ì‹¤í–‰)
    run_crawler = not args.no_crawler
    extractor.run(run_crawler=run_crawler)


if __name__ == "__main__":
    main()
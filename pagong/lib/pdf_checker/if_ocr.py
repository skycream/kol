"""
PDF OCR í•„ìš”ì„± íŒë‹¨ í´ë˜ìŠ¤
PDF íŒŒì¼ì´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê°€ëŠ¥í•œì§€, OCRì´ í•„ìš”í•œì§€ ì •í™•íˆ íŒë‹¨
"""
import fitz  # PyMuPDF
import os
from typing import Dict, Tuple, List, Optional
from dataclasses import dataclass
import re
from datetime import datetime
import warnings

# MuPDF ê²½ê³  ë° ì—ëŸ¬ ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings("ignore")
fitz.TOOLS.mupdf_display_errors(False)


@dataclass
class PDFAnalysisResult:
    """PDF ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    needs_ocr: bool
    pdf_type: str  # 'text', 'scanned', 'mixed', 'form', 'secured'
    confidence: float  # íŒë‹¨ ì‹ ë¢°ë„ (0.0 ~ 1.0)
    total_pages: int
    text_pages: int
    image_pages: int
    metadata: Dict
    reasons: List[str]
    recommendations: List[str]


class PDFOCRDetector:
    """PDF íŒŒì¼ì˜ OCR í•„ìš”ì„±ì„ ì •í™•íˆ íŒë‹¨í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.min_text_length = 10  # í˜ì´ì§€ë‹¹ ìµœì†Œ í…ìŠ¤íŠ¸ ê¸¸ì´
        self.min_text_ratio = 0.1  # ì´ë¯¸ì§€ ëŒ€ë¹„ í…ìŠ¤íŠ¸ ë¹„ìœ¨
        
    def analyze(self, pdf_path: str) -> PDFAnalysisResult:
        """PDF íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ OCR í•„ìš”ì„± íŒë‹¨"""
        
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        
        doc = fitz.open(pdf_path)
        
        # 1. ë©”íƒ€ë°ì´í„° ë¶„ì„
        metadata = self._analyze_metadata(doc)
        
        # 2. í˜ì´ì§€ë³„ ë¶„ì„
        page_analysis = self._analyze_pages(doc)
        
        # 3. í°íŠ¸ ì •ë³´ ë¶„ì„
        font_info = self._analyze_fonts(doc)
        
        # 4. ì¢…í•© íŒë‹¨
        result = self._make_decision(metadata, page_analysis, font_info, len(doc))
        
        doc.close()
        
        return result
    
    def _analyze_metadata(self, doc: fitz.Document) -> Dict:
        """PDF ë©”íƒ€ë°ì´í„° ë¶„ì„"""
        metadata = doc.metadata
        
        analysis = {
            'producer': metadata.get('producer', ''),
            'creator': metadata.get('creator', ''),
            'creation_date': metadata.get('creationDate', ''),
            'mod_date': metadata.get('modDate', ''),
            'format': metadata.get('format', ''),
            'encryption': metadata.get('encryption', ''),
            'title': metadata.get('title', ''),
            'author': metadata.get('author', ''),
            'subject': metadata.get('subject', ''),
        }
        
        # ìŠ¤ìº” ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        scan_keywords = ['scan', 'scanner', 'scanning', 'scanned', 'ocr', 'image']
        text_keywords = ['word', 'excel', 'powerpoint', 'libreoffice', 'pages', 'latex', 'tex']
        
        all_metadata_text = ' '.join(str(v).lower() for v in analysis.values() if v)
        
        analysis['has_scan_keywords'] = any(keyword in all_metadata_text for keyword in scan_keywords)
        analysis['has_text_keywords'] = any(keyword in all_metadata_text for keyword in text_keywords)
        analysis['is_tagged'] = doc.is_pdf  # Tagged PDFëŠ” ë³´í†µ ì ‘ê·¼ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ êµ¬ì¡° í¬í•¨
        
        return analysis
    
    def _analyze_pages(self, doc: fitz.Document) -> Dict:
        """ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë¶„ì„"""
        
        total_pages = len(doc)
        text_pages = 0
        image_pages = 0
        pure_text_pages = 0
        pure_image_pages = 0
        mixed_pages = 0
        
        page_details = []
        total_text_length = 0
        total_images = 0
        
        for page_num in range(total_pages):
            page = doc[page_num]
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = page.get_text()
            text_length = len(text.strip())
            
            # ì´ë¯¸ì§€ ì •ë³´
            image_list = page.get_images()
            image_count = len(image_list)
            
            # í…ìŠ¤íŠ¸ ë¸”ë¡ ë¶„ì„
            blocks = page.get_text("dict")
            text_blocks = [b for b in blocks["blocks"] if b["type"] == 0]  # type 0 = text
            
            # í°íŠ¸ í¬ê¸° ë¶„ì„ (ë Œë”ë§ëœ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸)
            font_sizes = []
            for block in text_blocks:
                for line in block.get("lines", []):
                    for span in line.get("spans", []):
                        if "size" in span:
                            font_sizes.append(span["size"])
            
            has_meaningful_text = text_length > self.min_text_length
            has_images = image_count > 0
            
            # í˜ì´ì§€ ìœ í˜• íŒë‹¨
            if has_meaningful_text and not has_images:
                pure_text_pages += 1
                text_pages += 1
            elif has_images and not has_meaningful_text:
                pure_image_pages += 1
                image_pages += 1
            elif has_meaningful_text and has_images:
                mixed_pages += 1
                text_pages += 1
                image_pages += 1
            
            # ì´ë¯¸ì§€ê°€ í˜ì´ì§€ ì „ì²´ë¥¼ ì°¨ì§€í•˜ëŠ”ì§€ í™•ì¸
            page_rect = page.rect
            page_area = page_rect.width * page_rect.height
            
            image_coverage = 0.0
            for img in image_list:
                try:
                    # ì´ë¯¸ì§€ ìœ„ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    img_rect = page.get_image_bbox(img)
                    if img_rect:
                        img_area = img_rect.width * img_rect.height
                        image_coverage = max(image_coverage, img_area / page_area)
                except:
                    pass
            
            page_details.append({
                'page_num': page_num + 1,
                'text_length': text_length,
                'image_count': image_count,
                'has_text': has_meaningful_text,
                'has_images': has_images,
                'font_sizes': font_sizes,
                'text_block_count': len(text_blocks),
                'image_coverage': image_coverage
            })
            
            total_text_length += text_length
            total_images += image_count
        
        return {
            'total_pages': total_pages,
            'text_pages': text_pages,
            'image_pages': image_pages,
            'pure_text_pages': pure_text_pages,
            'pure_image_pages': pure_image_pages,
            'mixed_pages': mixed_pages,
            'total_text_length': total_text_length,
            'total_images': total_images,
            'avg_text_per_page': total_text_length / total_pages if total_pages > 0 else 0,
            'page_details': page_details
        }
    
    def _analyze_fonts(self, doc: fitz.Document) -> Dict:
        """í°íŠ¸ ì •ë³´ ë¶„ì„ - ì„ë² ë””ë“œ í°íŠ¸ëŠ” ë³´í†µ ì‹¤ì œ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸"""
        
        font_list = []
        try:
            # ê° í˜ì´ì§€ì˜ í°íŠ¸ ì •ë³´ ìˆ˜ì§‘
            for page_num in range(len(doc)):
                page = doc[page_num]
                fonts = page.get_fonts()
                font_list.extend(fonts)
        except:
            pass
        
        # ê³ ìœ  í°íŠ¸ ì´ë¦„ ì¶”ì¶œ
        unique_fonts = set()
        embedded_fonts = 0
        system_fonts = 0
        
        for font in font_list:
            if len(font) >= 4:
                font_name = font[3]  # í°íŠ¸ ì´ë¦„
                unique_fonts.add(font_name)
                
                # ì„ë² ë””ë“œ í°íŠ¸ í™•ì¸ (ë³´í†µ '+' ê¸°í˜¸ë¡œ ì‹œì‘)
                if font_name.startswith('+'):
                    embedded_fonts += 1
                else:
                    system_fonts += 1
        
        return {
            'total_fonts': len(font_list),
            'unique_fonts': len(unique_fonts),
            'embedded_fonts': embedded_fonts,
            'system_fonts': system_fonts,
            'font_names': list(unique_fonts)[:10]  # ì²˜ìŒ 10ê°œë§Œ
        }
    
    def _make_decision(self, metadata: Dict, page_analysis: Dict, 
                      font_info: Dict, total_pages: int) -> PDFAnalysisResult:
        """ì¢…í•©ì ì¸ OCR í•„ìš”ì„± íŒë‹¨"""
        
        needs_ocr = False
        pdf_type = "unknown"
        confidence = 0.0
        reasons = []
        recommendations = []
        
        # ìŠ¤ìº”ë³¸ íŒë³„ í•µì‹¬ ê¸°ì¤€ (í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ìŠ¤ìº”ë³¸)
        scan_indicators = []
        
        # 1. Producerê°€ ìŠ¤ìºë„ˆ ì¥ì¹˜ì¸ì§€ í™•ì¸
        scanner_brands = ['sindoh', 'canon', 'hp', 'xerox', 'epson', 'ricoh', 
                         'konica', 'brother', 'fujitsu', 'kyocera', 'sharp']
        producer_lower = metadata.get('producer', '').lower()
        
        for brand in scanner_brands:
            if brand in producer_lower:
                scan_indicators.append(f"ìŠ¤ìºë„ˆ ì¥ì¹˜ë¡œ ìƒì„±ë¨: {metadata['producer']}")
                needs_ocr = True
                pdf_type = "scanned"
                break
        
        # 2. Creatorê°€ ìŠ¤ìº” ì†Œí”„íŠ¸ì›¨ì–´ì¸ì§€ í™•ì¸
        scan_software = ['adobe scan', 'camscanner', 'scansnap', 'paperport',
                        'abbyy', 'readiris', 'omnipage', 'pdf scanner']
        creator_lower = metadata.get('creator', '').lower()
        
        for software in scan_software:
            if software in creator_lower:
                scan_indicators.append(f"ìŠ¤ìº” ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ìƒì„±ë¨: {metadata['creator']}")
                needs_ocr = True
                pdf_type = "scanned"
                break
        
        # 3. í°íŠ¸ ì •ë³´ê°€ ì—†ëŠ”ì§€ í™•ì¸
        if font_info['total_fonts'] == 0 and page_analysis.get('total_images', 0) > 0:
            scan_indicators.append("í°íŠ¸ ì •ë³´ ì—†ìŒ + ì´ë¯¸ì§€ ì¡´ì¬ (ìŠ¤ìº” ë¬¸ì„œ)")
            needs_ocr = True
            pdf_type = "scanned"
        
        # 4. í˜ì´ì§€ê°€ 100% ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
        if page_analysis['pure_image_pages'] == total_pages and total_pages > 0:
            scan_indicators.append("ëª¨ë“  í˜ì´ì§€ê°€ ì´ë¯¸ì§€ë¡œë§Œ êµ¬ì„±")
            needs_ocr = True
            pdf_type = "scanned"
        
        # 5. í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ëŠ”ì§€ í™•ì¸ (í˜ì´ì§€ë‹¹ 10ì ë¯¸ë§Œ)
        if page_analysis['avg_text_per_page'] < 10 and page_analysis.get('total_images', 0) > 0:
            scan_indicators.append(f"í…ìŠ¤íŠ¸ ê±°ì˜ ì—†ìŒ ({page_analysis['avg_text_per_page']:.0f}ì/í˜ì´ì§€)")
            needs_ocr = True
            pdf_type = "scanned"
        
        # ìŠ¤ìº”ë³¸ì´ ì•„ë‹Œ ê²½ìš° ì¶”ê°€ íŒë‹¨
        if not needs_ocr:
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ PDF í™•ì¸
            if page_analysis['pure_text_pages'] == total_pages:
                pdf_type = "text"
                reasons.append("ëª¨ë“  í˜ì´ì§€ê°€ í…ìŠ¤íŠ¸ë¡œë§Œ êµ¬ì„±")
                confidence = 0.9
            elif page_analysis['avg_text_per_page'] > 500:
                pdf_type = "text"
                reasons.append(f"í˜ì´ì§€ë‹¹ ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ í¬í•¨ ({page_analysis['avg_text_per_page']:.0f}ì)")
                confidence = 0.8
            elif page_analysis['text_pages'] > 0 and page_analysis['image_pages'] > 0:
                pdf_type = "mixed"
                reasons.append("í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ í˜¼í•©ëœ ë¬¸ì„œ")
                confidence = 0.7
            else:
                pdf_type = "text"
                confidence = 0.5
        else:
            # ìŠ¤ìº”ë³¸ì¸ ê²½ìš°
            reasons = scan_indicators
            confidence = 0.9 if len(scan_indicators) >= 2 else 0.8
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if needs_ocr:
            recommendations.append("OCR ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            if page_analysis['total_images'] > 0:
                recommendations.append("ê³ í’ˆì§ˆ OCRì„ ìœ„í•´ 300 DPI ì´ìƒ ê¶Œì¥")
            if 'scanner' in metadata.get('producer', '').lower():
                recommendations.append("ìŠ¤ìºë„ˆ ì„¤ì •ì—ì„œ í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì˜µì…˜ í™œì„±í™” ê²€í† ")
        else:
            recommendations.append("í…ìŠ¤íŠ¸ ì§ì ‘ ì¶”ì¶œ ê°€ëŠ¥")
            if pdf_type == "mixed":
                recommendations.append("ì¼ë¶€ ì´ë¯¸ì§€ëŠ” ë³„ë„ OCR ì²˜ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ")
        
        return PDFAnalysisResult(
            needs_ocr=needs_ocr,
            pdf_type=pdf_type,
            confidence=confidence,
            total_pages=total_pages,
            text_pages=page_analysis['text_pages'],
            image_pages=page_analysis['image_pages'],
            metadata=metadata,
            reasons=reasons,
            recommendations=recommendations
        )
    
    def quick_check(self, pdf_path: str) -> bool:
        """ë¹ ë¥¸ OCR í•„ìš”ì„± ì²´í¬ (True/Falseë§Œ ë°˜í™˜)"""
        try:
            result = self.analyze(pdf_path)
            return result.needs_ocr
        except:
            return True  # ì˜¤ë¥˜ ì‹œ OCR í•„ìš”ë¡œ ê°€ì •


def main():
    """í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš© ì˜ˆì‹œ"""
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python if_ocr.py [PDFíŒŒì¼ê²½ë¡œ]")
        print("\nì˜ˆì‹œ:")
        print("  python if_ocr.py test.pdf")
        return
    
    pdf_path = sys.argv[1]
    
    # OCR í•„ìš”ì„± ê²€ì‚¬
    detector = PDFOCRDetector()
    
    try:
        # ìƒì„¸ ë¶„ì„
        result = detector.analyze(pdf_path)
        
        print(f"\nğŸ“„ PDF ë¶„ì„ ê²°ê³¼: {os.path.basename(pdf_path)}")
        print("=" * 60)
        
        # í•µì‹¬ íŒë‹¨
        ocr_status = "â­• í•„ìš”" if result.needs_ocr else "âŒ ë¶ˆí•„ìš”"
        print(f"ğŸ” OCR í•„ìš”ì„±: {ocr_status}")
        print(f"ğŸ“Š PDF ìœ í˜•: {result.pdf_type}")
        print(f"ğŸ¯ íŒë‹¨ ì‹ ë¢°ë„: {result.confidence:.0%}")
        
        # í˜ì´ì§€ ì •ë³´
        print(f"\nğŸ“„ í˜ì´ì§€ ì •ë³´:")
        print(f"  - ì „ì²´: {result.total_pages}í˜ì´ì§€")
        print(f"  - í…ìŠ¤íŠ¸ í¬í•¨: {result.text_pages}í˜ì´ì§€")
        print(f"  - ì´ë¯¸ì§€ í¬í•¨: {result.image_pages}í˜ì´ì§€")
        
        # íŒë‹¨ ê·¼ê±°
        print(f"\nğŸ’­ íŒë‹¨ ê·¼ê±°:")
        for reason in result.reasons:
            print(f"  â€¢ {reason}")
        
        # ë©”íƒ€ë°ì´í„° ì¼ë¶€
        print(f"\nğŸ“‹ ë©”íƒ€ë°ì´í„°:")
        if result.metadata.get('producer'):
            print(f"  - ìƒì„± í”„ë¡œê·¸ë¨: {result.metadata['producer']}")
        if result.metadata.get('creator'):
            print(f"  - ì‘ì„± í”„ë¡œê·¸ë¨: {result.metadata['creator']}")
        
        # ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in result.recommendations:
            print(f"  â€¢ {rec}")
        
        # ë¹ ë¥¸ ì²´í¬ ì˜ˆì‹œ
        print(f"\nâš¡ ë¹ ë¥¸ ì²´í¬ ê²°ê³¼: OCR {'í•„ìš”' if detector.quick_check(pdf_path) else 'ë¶ˆí•„ìš”'}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
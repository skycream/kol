"""
PDF ë©”íƒ€ë°ì´í„° ìƒì„¸ ë¶„ì„ ë„êµ¬
ìŠ¤ìº”ë³¸ êµ¬ë³„ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„° íŒ¨í„´ ë¶„ì„
"""
import fitz
import os
import sys
from datetime import datetime
from typing import Dict, List
import json
from pathlib import Path

# MuPDF ì—ëŸ¬ ì–µì œ
fitz.TOOLS.mupdf_display_errors(False)


class PDFMetadataAnalyzer:
    """PDF ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„¸íˆ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ìŠ¤ìºë„ˆ ê´€ë ¨ í‚¤ì›Œë“œ
        self.scanner_keywords = [
            'scan', 'scanner', 'scanning', 'scanned', 
            'ocr', 'image', 'capture', 'digitiz',
            # ì£¼ìš” ìŠ¤ìºë„ˆ ë¸Œëœë“œ
            'canon', 'epson', 'hp', 'xerox', 'ricoh', 'konica', 'brother',
            'fujitsu', 'sindoh', 'kyocera',
            # ìŠ¤ìº” ì†Œí”„íŠ¸ì›¨ì–´
            'adobe scan', 'camscanner', 'scansnap', 'paperport',
            'abbyy', 'readiris', 'omnipage',
            # í•œêµ­ì–´
            'ìŠ¤ìº”', 'ìŠ¤ìºë„ˆ', 'ë³µì‚¬ê¸°'
        ]
        
        # ë¬¸ì„œ ìƒì„± ì†Œí”„íŠ¸ì›¨ì–´ í‚¤ì›Œë“œ
        self.document_software_keywords = [
            # ì˜¤í”¼ìŠ¤
            'microsoft', 'word', 'excel', 'powerpoint', 'office',
            'libreoffice', 'openoffice', 'pages', 'numbers',
            # PDF ìƒì„±ê¸°
            'acrobat', 'pdfcreator', 'cutepdf', 'primopdf',
            'ghostscript', 'wkhtmltopdf', 'chrome',
            # í•œê¸€ ì˜¤í”¼ìŠ¤
            'hancom', 'hwp', 'í•œê¸€', 'í•œì»´',
            # ê¸°íƒ€
            'latex', 'tex', 'writer'
        ]
        
    def analyze_metadata(self, pdf_path: str) -> Dict:
        """PDF ë©”íƒ€ë°ì´í„° ìƒì„¸ ë¶„ì„"""
        
        doc = fitz.open(pdf_path)
        
        # 1. ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
        metadata = doc.metadata
        
        # 2. í™•ì¥ ë©”íƒ€ë°ì´í„°
        extended_info = {
            'filename': os.path.basename(pdf_path),
            'file_size': os.path.getsize(pdf_path),
            'page_count': len(doc),
            'is_encrypted': doc.is_encrypted,
            'is_form_pdf': doc.is_form_pdf,
            'is_reflowable': doc.is_reflowable,
            'is_repaired': doc.is_repaired,
            'permissions': doc.permissions,
        }
        
        # 3. ìƒì„±/ìˆ˜ì • ë‚ ì§œ íŒŒì‹±
        dates = self._parse_dates(metadata)
        
        # 4. Producer/Creator ë¶„ì„
        producer_analysis = self._analyze_producer_creator(metadata)
        
        # 5. í˜ì´ì§€ë³„ íŠ¹ì„± ë¶„ì„
        page_analysis = self._analyze_pages(doc)
        
        # 6. í°íŠ¸ ë¶„ì„
        font_analysis = self._analyze_fonts(doc)
        
        # 7. ìŠ¤ìº” íŒë³„ ì ìˆ˜
        scan_score = self._calculate_scan_score(
            metadata, producer_analysis, page_analysis, font_analysis
        )
        
        doc.close()
        
        return {
            'basic_metadata': metadata,
            'extended_info': extended_info,
            'dates': dates,
            'producer_analysis': producer_analysis,
            'page_analysis': page_analysis,
            'font_analysis': font_analysis,
            'scan_score': scan_score,
            'is_likely_scanned': scan_score['is_likely_scanned']
        }
    
    def _parse_dates(self, metadata: Dict) -> Dict:
        """ë‚ ì§œ ì •ë³´ íŒŒì‹±"""
        dates = {}
        
        for key in ['creationDate', 'modDate']:
            if key in metadata and metadata[key]:
                try:
                    # PDF ë‚ ì§œ í˜•ì‹: D:20231225123456+09'00'
                    date_str = metadata[key]
                    if date_str.startswith('D:'):
                        date_str = date_str[2:]
                    # ê°„ë‹¨í•œ íŒŒì‹± (ë…„ì›”ì¼ì‹œë¶„ì´ˆë§Œ)
                    year = date_str[0:4]
                    month = date_str[4:6]
                    day = date_str[6:8]
                    hour = date_str[8:10] if len(date_str) > 8 else '00'
                    minute = date_str[10:12] if len(date_str) > 10 else '00'
                    
                    dates[key] = f"{year}-{month}-{day} {hour}:{minute}"
                except:
                    dates[key] = metadata[key]
        
        return dates
    
    def _analyze_producer_creator(self, metadata: Dict) -> Dict:
        """Producer/Creator ë¶„ì„"""
        producer = metadata.get('producer', '').lower()
        creator = metadata.get('creator', '').lower()
        
        analysis = {
            'producer': metadata.get('producer', ''),
            'creator': metadata.get('creator', ''),
            'has_scanner_keywords': False,
            'has_document_keywords': False,
            'scanner_matches': [],
            'document_matches': [],
            'producer_type': 'unknown'
        }
        
        # ìŠ¤ìºë„ˆ í‚¤ì›Œë“œ ê²€ìƒ‰
        for keyword in self.scanner_keywords:
            if keyword in producer or keyword in creator:
                analysis['has_scanner_keywords'] = True
                analysis['scanner_matches'].append(keyword)
        
        # ë¬¸ì„œ ì†Œí”„íŠ¸ì›¨ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰
        for keyword in self.document_software_keywords:
            if keyword in producer or keyword in creator:
                analysis['has_document_keywords'] = True
                analysis['document_matches'].append(keyword)
        
        # Producer ìœ í˜• íŒë‹¨
        if analysis['has_scanner_keywords']:
            analysis['producer_type'] = 'scanner'
        elif analysis['has_document_keywords']:
            analysis['producer_type'] = 'document_software'
        elif producer or creator:
            analysis['producer_type'] = 'other'
        
        return analysis
    
    def _analyze_pages(self, doc: fitz.Document) -> Dict:
        """í˜ì´ì§€ íŠ¹ì„± ë¶„ì„"""
        total_text_length = 0
        pages_with_text = 0
        pages_with_images = 0
        pages_with_only_images = 0
        image_coverage_ratios = []
        
        for page in doc:
            text = page.get_text()
            text_length = len(text.strip())
            images = page.get_images()
            
            if text_length > 10:
                pages_with_text += 1
            
            if images:
                pages_with_images += 1
                
            if images and text_length < 10:
                pages_with_only_images += 1
            
            # ì´ë¯¸ì§€ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
            if images:
                page_area = page.rect.width * page.rect.height
                total_image_area = 0
                
                for img in images:
                    try:
                        bbox = page.get_image_bbox(img)
                        if bbox:
                            img_area = bbox.width * bbox.height
                            total_image_area += img_area
                    except:
                        pass
                
                if page_area > 0:
                    coverage = total_image_area / page_area
                    image_coverage_ratios.append(coverage)
            
            total_text_length += text_length
        
        return {
            'total_pages': len(doc),
            'pages_with_text': pages_with_text,
            'pages_with_images': pages_with_images,
            'pages_with_only_images': pages_with_only_images,
            'avg_text_per_page': total_text_length / len(doc) if len(doc) > 0 else 0,
            'text_page_ratio': pages_with_text / len(doc) if len(doc) > 0 else 0,
            'image_only_ratio': pages_with_only_images / len(doc) if len(doc) > 0 else 0,
            'avg_image_coverage': sum(image_coverage_ratios) / len(image_coverage_ratios) if image_coverage_ratios else 0
        }
    
    def _analyze_fonts(self, doc: fitz.Document) -> Dict:
        """í°íŠ¸ ì •ë³´ ë¶„ì„"""
        all_fonts = []
        embedded_fonts = set()
        system_fonts = set()
        
        for page in doc:
            fonts = page.get_fonts()
            for font in fonts:
                if len(font) >= 4:
                    font_name = font[3]
                    all_fonts.append(font_name)
                    
                    if font_name.startswith('+'):
                        embedded_fonts.add(font_name)
                    else:
                        system_fonts.add(font_name)
        
        return {
            'total_font_count': len(all_fonts),
            'unique_font_count': len(set(all_fonts)),
            'embedded_font_count': len(embedded_fonts),
            'system_font_count': len(system_fonts),
            'has_fonts': len(all_fonts) > 0,
            'font_names': list(set(all_fonts))[:10]  # ì²˜ìŒ 10ê°œë§Œ
        }
    
    def _calculate_scan_score(self, metadata: Dict, producer_analysis: Dict, 
                            page_analysis: Dict, font_analysis: Dict) -> Dict:
        """ìŠ¤ìº” ë¬¸ì„œ íŒë³„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        score = 0
        reasons = []
        is_scanned = False
        
        # í•µì‹¬ ìŠ¤ìº” ì§€í‘œ - í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ë†’ì€ ì ìˆ˜
        
        # 1. Producerê°€ ìŠ¤ìºë„ˆ ì¥ì¹˜ë©´ ì¦‰ì‹œ 100ì 
        if producer_analysis['producer_type'] == 'scanner':
            score = 100
            is_scanned = True
            reasons.append(f"ìŠ¤ìºë„ˆ ì¥ì¹˜ë¡œ ìƒì„±ë¨: {producer_analysis['producer']}")
        
        # 2. Creatorê°€ ìŠ¤ìº” ì†Œí”„íŠ¸ì›¨ì–´ë©´ ì¦‰ì‹œ 100ì 
        elif producer_analysis['has_scanner_keywords'] and 'creator' in producer_analysis:
            score = 100
            is_scanned = True
            reasons.append(f"ìŠ¤ìº” ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ìƒì„±ë¨: {producer_analysis['creator']}")
        
        # 3. í°íŠ¸ ì •ë³´ ì—†ìŒ + ì´ë¯¸ì§€ ìˆìŒ = 95ì 
        elif not font_analysis['has_fonts'] and page_analysis.get('total_images', 0) > 0:
            score = 95
            is_scanned = True
            reasons.append("í°íŠ¸ ì •ë³´ ì—†ìŒ + ì´ë¯¸ì§€ ì¡´ì¬ (ìŠ¤ìº” ë¬¸ì„œ)")
        
        # 4. ëª¨ë“  í˜ì´ì§€ê°€ ì´ë¯¸ì§€ë¡œë§Œ êµ¬ì„± = 95ì 
        elif page_analysis.get('image_only_ratio', 0) == 1.0:
            score = 95
            is_scanned = True
            reasons.append("ëª¨ë“  í˜ì´ì§€ê°€ ì´ë¯¸ì§€ë¡œë§Œ êµ¬ì„±")
        
        # 5. í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìŒ (í˜ì´ì§€ë‹¹ 10ì ë¯¸ë§Œ) + ì´ë¯¸ì§€ ìˆìŒ = 90ì 
        elif page_analysis.get('avg_text_per_page', 0) < 10 and page_analysis.get('total_images', 0) > 0:
            score = 90
            is_scanned = True
            reasons.append(f"í…ìŠ¤íŠ¸ ê±°ì˜ ì—†ìŒ ({page_analysis.get('avg_text_per_page', 0):.0f}ì/í˜ì´ì§€)")
        
        # ìŠ¤ìº”ë³¸ì´ ì•„ë‹Œ ê²½ìš° ì¶”ê°€ ë¶„ì„
        if not is_scanned:
            # ë¬¸ì„œ ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ìƒì„±ëœ ê²½ìš°
            if producer_analysis['producer_type'] == 'document_software':
                score = 5
                reasons.append(f"ë¬¸ì„œ í¸ì§‘ ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ìƒì„±: {producer_analysis['document_matches']}")
            
            # ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°
            elif page_analysis['avg_text_per_page'] > 500:
                score = 5
                reasons.append(f"í˜ì´ì§€ë‹¹ ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ ({page_analysis['avg_text_per_page']:.0f}ì)")
            
            # í°íŠ¸ ì •ë³´ê°€ í’ë¶€í•œ ê²½ìš°
            elif font_analysis['embedded_font_count'] > 0:
                score = 10
                reasons.append(f"ì„ë² ë””ë“œ í°íŠ¸ {font_analysis['embedded_font_count']}ê°œ í¬í•¨")
            
            # ê¸°ë³¸ê°’
            else:
                score = 20
                reasons.append("ëª…í™•í•œ ìŠ¤ìº” ì§€í‘œ ì—†ìŒ")
        
        return {
            'total_score': score,
            'reasons': reasons,
            'is_likely_scanned': score >= 70,
            'confidence': 'high' if score >= 90 else 'medium' if score >= 70 else 'low'
        }
    
    def print_analysis(self, analysis: Dict):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“‹ PDF ë©”íƒ€ë°ì´í„° ìƒì„¸ ë¶„ì„")
        print("="*80)
        
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
        print("\nğŸ“Œ ê¸°ë³¸ ë©”íƒ€ë°ì´í„°:")
        for key, value in analysis['basic_metadata'].items():
            if value:
                print(f"  - {key}: {value}")
        
        # Producer/Creator ë¶„ì„
        print(f"\nğŸ” Producer/Creator ë¶„ì„:")
        prod = analysis['producer_analysis']
        print(f"  - Producer: {prod['producer'] or 'ì—†ìŒ'}")
        print(f"  - Creator: {prod['creator'] or 'ì—†ìŒ'}")
        print(f"  - ìœ í˜•: {prod['producer_type']}")
        if prod['scanner_matches']:
            print(f"  - ìŠ¤ìºë„ˆ í‚¤ì›Œë“œ: {', '.join(prod['scanner_matches'])}")
        if prod['document_matches']:
            print(f"  - ë¬¸ì„œ SW í‚¤ì›Œë“œ: {', '.join(prod['document_matches'])}")
        
        # í˜ì´ì§€ ë¶„ì„
        print(f"\nğŸ“„ í˜ì´ì§€ ë¶„ì„:")
        page = analysis['page_analysis']
        print(f"  - ì´ í˜ì´ì§€: {page['total_pages']}")
        print(f"  - í…ìŠ¤íŠ¸ ìˆëŠ” í˜ì´ì§€: {page['pages_with_text']} ({page['text_page_ratio']:.0%})")
        print(f"  - ì´ë¯¸ì§€ë§Œ ìˆëŠ” í˜ì´ì§€: {page['pages_with_only_images']} ({page['image_only_ratio']:.0%})")
        print(f"  - í‰ê·  í…ìŠ¤íŠ¸/í˜ì´ì§€: {page['avg_text_per_page']:.0f}ì")
        print(f"  - í‰ê·  ì´ë¯¸ì§€ ì»¤ë²„ë¦¬ì§€: {page['avg_image_coverage']:.0%}")
        
        # í°íŠ¸ ë¶„ì„
        print(f"\nğŸ”¤ í°íŠ¸ ë¶„ì„:")
        font = analysis['font_analysis']
        print(f"  - í°íŠ¸ ì¡´ì¬: {'ì˜ˆ' if font['has_fonts'] else 'ì•„ë‹ˆì˜¤'}")
        if font['has_fonts']:
            print(f"  - ê³ ìœ  í°íŠ¸ ìˆ˜: {font['unique_font_count']}")
            print(f"  - ì„ë² ë””ë“œ í°íŠ¸: {font['embedded_font_count']}")
            print(f"  - ì‹œìŠ¤í…œ í°íŠ¸: {font['system_font_count']}")
        
        # ìŠ¤ìº” íŒë³„ ê²°ê³¼
        print(f"\nğŸ¯ ìŠ¤ìº” ë¬¸ì„œ íŒë³„:")
        scan = analysis['scan_score']
        print(f"  - ìŠ¤ìº” ì ìˆ˜: {scan['total_score']}/100")
        print(f"  - íŒì •: {'ìŠ¤ìº” ë¬¸ì„œ' if analysis['is_likely_scanned'] else 'ë””ì§€í„¸ ë¬¸ì„œ'}")
        print(f"  - íŒë³„ ê·¼ê±°:")
        for reason in scan['reasons']:
            print(f"    â€¢ {reason}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python pdf_metadata_analyzer.py [PDFíŒŒì¼]")
        return
    
    pdf_path = sys.argv[1]
    
    if not os.path.exists(pdf_path):
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return
    
    analyzer = PDFMetadataAnalyzer()
    
    try:
        # ë¶„ì„ ì‹¤í–‰
        analysis = analyzer.analyze_metadata(pdf_path)
        
        # ê²°ê³¼ ì¶œë ¥
        analyzer.print_analysis(analysis)
        
        # JSONìœ¼ë¡œ ì €ì¥ ì˜µì…˜
        if len(sys.argv) > 2 and sys.argv[2] == '--save':
            output_file = Path(pdf_path).stem + '_metadata.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
            print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    main()